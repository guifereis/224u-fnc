{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "import re\n",
    "import nltk\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from functools import partial\n",
    "import ipywidgets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from rewrite.scorer import score_4class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_hdf(\"X_train_full_allfeatures-NOLABEL.h5\", key=\"df\")\n",
    "y_train = pd.read_hdf(\"y_train_full.h5\", key=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    unrelated\n",
       "1        agree\n",
       "2    unrelated\n",
       "3    unrelated\n",
       "4     disagree\n",
       "Name: Stance, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>___clean_headline</th>\n",
       "      <th>___clean_headline_tokenized_lemmas</th>\n",
       "      <th>___clean_body</th>\n",
       "      <th>___clean_body_tokenized_lemmas</th>\n",
       "      <th>bin_count</th>\n",
       "      <th>bin_count_early</th>\n",
       "      <th>bin_count_stopless</th>\n",
       "      <th>word_overlap_features</th>\n",
       "      <th>...</th>\n",
       "      <th>chargram_2_first_hits</th>\n",
       "      <th>chargram_8_hits</th>\n",
       "      <th>chargram_8_early_hits</th>\n",
       "      <th>chargram_8_first_hits</th>\n",
       "      <th>chargram_4_hits</th>\n",
       "      <th>chargram_4_early_hits</th>\n",
       "      <th>chargram_4_first_hits</th>\n",
       "      <th>chargram_16_hits</th>\n",
       "      <th>chargram_16_early_hits</th>\n",
       "      <th>chargram_16_first_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\n\\n...</td>\n",
       "      <td>police find mass graves with at least 15 bodie...</td>\n",
       "      <td>[police, find, mass, graf, with, at, least, 15...</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "      <td>[danny, boyle, is, directing, the, untitled, f...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>[hundred, of, palestinian, flee, flood, in, ga...</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "      <td>[hundred, of, palestinian, were, evacuated, fr...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>[christian, bale, pass, on, role, of, steve, j...</td>\n",
       "      <td>30 year old moscow resident was hospitalized w...</td>\n",
       "      <td>[30, year, old, moscow, resident, wa, hospital...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "      <td>hbo and apple in talks for 15 month apple tv s...</td>\n",
       "      <td>[hbo, and, apple, in, talk, for, 15, month, ap...</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "      <td>[reuters, a, canadian, soldier, wa, shot, at, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>[spider, burrowed, through, tourist, s, stomac...</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "      <td>[fear, not, arachnophobes, the, story, of, bun...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032727</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  Police find mass graves with at least '15 bodi...   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...   \n",
       "4  Spider burrowed through tourist's stomach and ...   \n",
       "\n",
       "                                         articleBody  \\\n",
       "0  Danny Boyle is directing the untitled film\\n\\n...   \n",
       "1  Hundreds of Palestinians were evacuated from t...   \n",
       "2  30-year-old Moscow resident was hospitalized w...   \n",
       "3  (Reuters) - A Canadian soldier was shot at the...   \n",
       "4  Fear not arachnophobes, the story of Bunbury's...   \n",
       "\n",
       "                                   ___clean_headline  \\\n",
       "0  police find mass graves with at least 15 bodie...   \n",
       "1  hundreds of palestinians flee floods in gaza a...   \n",
       "2  christian bale passes on role of steve jobs ac...   \n",
       "3  hbo and apple in talks for 15 month apple tv s...   \n",
       "4  spider burrowed through tourist s stomach and ...   \n",
       "\n",
       "                  ___clean_headline_tokenized_lemmas  \\\n",
       "0  [police, find, mass, graf, with, at, least, 15...   \n",
       "1  [hundred, of, palestinian, flee, flood, in, ga...   \n",
       "2  [christian, bale, pass, on, role, of, steve, j...   \n",
       "3  [hbo, and, apple, in, talk, for, 15, month, ap...   \n",
       "4  [spider, burrowed, through, tourist, s, stomac...   \n",
       "\n",
       "                                       ___clean_body  \\\n",
       "0  danny boyle is directing the untitled film set...   \n",
       "1  hundreds of palestinians were evacuated from t...   \n",
       "2  30 year old moscow resident was hospitalized w...   \n",
       "3  reuters a canadian soldier was shot at the can...   \n",
       "4  fear not arachnophobes the story of bunbury s ...   \n",
       "\n",
       "                      ___clean_body_tokenized_lemmas  bin_count  \\\n",
       "0  [danny, boyle, is, directing, the, untitled, f...          2   \n",
       "1  [hundred, of, palestinian, were, evacuated, fr...         10   \n",
       "2  [30, year, old, moscow, resident, wa, hospital...          5   \n",
       "3  [reuters, a, canadian, soldier, wa, shot, at, ...          3   \n",
       "4  [fear, not, arachnophobes, the, story, of, bun...          9   \n",
       "\n",
       "   bin_count_early  bin_count_stopless  word_overlap_features  \\\n",
       "0                0                   0               0.014085   \n",
       "1                7                   7               0.046083   \n",
       "2                4                   1               0.030303   \n",
       "3                3                   0               0.028169   \n",
       "4                5                   4               0.032727   \n",
       "\n",
       "            ...            chargram_2_first_hits  chargram_8_hits  \\\n",
       "0           ...                                0                0   \n",
       "1           ...                                3                0   \n",
       "2           ...                                1                0   \n",
       "3           ...                                1                0   \n",
       "4           ...                                4                0   \n",
       "\n",
       "   chargram_8_early_hits  chargram_8_first_hits  chargram_4_hits  \\\n",
       "0                      0                      0                0   \n",
       "1                      0                      0                0   \n",
       "2                      0                      0                0   \n",
       "3                      0                      0                0   \n",
       "4                      0                      0                0   \n",
       "\n",
       "   chargram_4_early_hits  chargram_4_first_hits  chargram_16_hits  \\\n",
       "0                      0                      0                 0   \n",
       "1                      0                      0                 0   \n",
       "2                      0                      0                 0   \n",
       "3                      0                      0                 0   \n",
       "4                      0                      0                 0   \n",
       "\n",
       "   chargram_16_early_hits  chargram_16_first_hits  \n",
       "0                       0                       0  \n",
       "1                       0                       0  \n",
       "2                       0                       0  \n",
       "3                       0                       0  \n",
       "4                       0                       0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 49)\n",
      "(49972,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_str_cols(df): # df should be X, e.g. X_train or X_dev\n",
    "    del df[\"articleBody\"]\n",
    "    del df[\"Headline\"]\n",
    "    for col_name in df.columns:\n",
    "        if \"___\" == col_name[0:3]:\n",
    "            del df[col_name]\n",
    "#del_str_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 50)\n"
     ]
    }
   ],
   "source": [
    "Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "print(Xy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>___clean_headline</th>\n",
       "      <th>___clean_headline_tokenized_lemmas</th>\n",
       "      <th>___clean_body</th>\n",
       "      <th>___clean_body_tokenized_lemmas</th>\n",
       "      <th>bin_count</th>\n",
       "      <th>bin_count_early</th>\n",
       "      <th>bin_count_stopless</th>\n",
       "      <th>word_overlap_features</th>\n",
       "      <th>...</th>\n",
       "      <th>chargram_8_hits</th>\n",
       "      <th>chargram_8_early_hits</th>\n",
       "      <th>chargram_8_first_hits</th>\n",
       "      <th>chargram_4_hits</th>\n",
       "      <th>chargram_4_early_hits</th>\n",
       "      <th>chargram_4_first_hits</th>\n",
       "      <th>chargram_16_hits</th>\n",
       "      <th>chargram_16_early_hits</th>\n",
       "      <th>chargram_16_first_hits</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\n\\n...</td>\n",
       "      <td>police find mass graves with at least 15 bodie...</td>\n",
       "      <td>[police, find, mass, graf, with, at, least, 15...</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "      <td>[danny, boyle, is, directing, the, untitled, f...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>[hundred, of, palestinian, flee, flood, in, ga...</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "      <td>[hundred, of, palestinian, were, evacuated, fr...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>[christian, bale, pass, on, role, of, steve, j...</td>\n",
       "      <td>30 year old moscow resident was hospitalized w...</td>\n",
       "      <td>[30, year, old, moscow, resident, wa, hospital...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "      <td>hbo and apple in talks for 15 month apple tv s...</td>\n",
       "      <td>[hbo, and, apple, in, talk, for, 15, month, ap...</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "      <td>[reuters, a, canadian, soldier, wa, shot, at, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>[spider, burrowed, through, tourist, s, stomac...</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "      <td>[fear, not, arachnophobes, the, story, of, bun...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  Police find mass graves with at least '15 bodi...   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...   \n",
       "4  Spider burrowed through tourist's stomach and ...   \n",
       "\n",
       "                                         articleBody  \\\n",
       "0  Danny Boyle is directing the untitled film\\n\\n...   \n",
       "1  Hundreds of Palestinians were evacuated from t...   \n",
       "2  30-year-old Moscow resident was hospitalized w...   \n",
       "3  (Reuters) - A Canadian soldier was shot at the...   \n",
       "4  Fear not arachnophobes, the story of Bunbury's...   \n",
       "\n",
       "                                   ___clean_headline  \\\n",
       "0  police find mass graves with at least 15 bodie...   \n",
       "1  hundreds of palestinians flee floods in gaza a...   \n",
       "2  christian bale passes on role of steve jobs ac...   \n",
       "3  hbo and apple in talks for 15 month apple tv s...   \n",
       "4  spider burrowed through tourist s stomach and ...   \n",
       "\n",
       "                  ___clean_headline_tokenized_lemmas  \\\n",
       "0  [police, find, mass, graf, with, at, least, 15...   \n",
       "1  [hundred, of, palestinian, flee, flood, in, ga...   \n",
       "2  [christian, bale, pass, on, role, of, steve, j...   \n",
       "3  [hbo, and, apple, in, talk, for, 15, month, ap...   \n",
       "4  [spider, burrowed, through, tourist, s, stomac...   \n",
       "\n",
       "                                       ___clean_body  \\\n",
       "0  danny boyle is directing the untitled film set...   \n",
       "1  hundreds of palestinians were evacuated from t...   \n",
       "2  30 year old moscow resident was hospitalized w...   \n",
       "3  reuters a canadian soldier was shot at the can...   \n",
       "4  fear not arachnophobes the story of bunbury s ...   \n",
       "\n",
       "                      ___clean_body_tokenized_lemmas  bin_count  \\\n",
       "0  [danny, boyle, is, directing, the, untitled, f...          2   \n",
       "1  [hundred, of, palestinian, were, evacuated, fr...         10   \n",
       "2  [30, year, old, moscow, resident, wa, hospital...          5   \n",
       "3  [reuters, a, canadian, soldier, wa, shot, at, ...          3   \n",
       "4  [fear, not, arachnophobes, the, story, of, bun...          9   \n",
       "\n",
       "   bin_count_early  bin_count_stopless  word_overlap_features    ...      \\\n",
       "0                0                   0               0.014085    ...       \n",
       "1                7                   7               0.046083    ...       \n",
       "2                4                   1               0.030303    ...       \n",
       "3                3                   0               0.028169    ...       \n",
       "4                5                   4               0.032727    ...       \n",
       "\n",
       "   chargram_8_hits  chargram_8_early_hits  chargram_8_first_hits  \\\n",
       "0                0                      0                      0   \n",
       "1                0                      0                      0   \n",
       "2                0                      0                      0   \n",
       "3                0                      0                      0   \n",
       "4                0                      0                      0   \n",
       "\n",
       "   chargram_4_hits  chargram_4_early_hits  chargram_4_first_hits  \\\n",
       "0                0                      0                      0   \n",
       "1                0                      0                      0   \n",
       "2                0                      0                      0   \n",
       "3                0                      0                      0   \n",
       "4                0                      0                      0   \n",
       "\n",
       "   chargram_16_hits  chargram_16_early_hits  chargram_16_first_hits     Stance  \n",
       "0                 0                       0                       0  unrelated  \n",
       "1                 0                       0                       0      agree  \n",
       "2                 0                       0                       0  unrelated  \n",
       "3                 0                       0                       0  unrelated  \n",
       "4                 0                       0                       0   disagree  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xy_train = Xy_train[Xy_train[\"Stance\"] != \"unrelated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 50)\n"
     ]
    }
   ],
   "source": [
    "print(Xy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 49)\n",
      "(49972,)\n"
     ]
    }
   ],
   "source": [
    "y_train = Xy_train[\"Stance\"]\n",
    "X_train = Xy_train.drop(\"Stance\", axis=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import vader\n",
    "sid = vader.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49972/49972 [00:28<00:00, 1767.72it/s]\n",
      "100%|██████████| 49972/49972 [04:41<00:00, 177.42it/s] \n"
     ]
    }
   ],
   "source": [
    "def vader_polarity_scores(df, text_col_name, col_name_prefix):\n",
    "    pol_scores = df[text_col_name].progress_apply(lambda hl: pd.Series(sid.polarity_scores(hl)))\n",
    "    cols = pol_scores.columns\n",
    "    new_cols = []\n",
    "    for col_name in cols:\n",
    "        new_cols.append(\"vader_\"+col_name_prefix+\"_\"+col_name)\n",
    "    pol_scores.columns = new_cols\n",
    "    return pol_scores\n",
    "\n",
    "vader_hl_df = vader_polarity_scores(X_train, \"Headline\", \"hl\")\n",
    "vader_body_df = vader_polarity_scores(X_train, \"articleBody\", \"body\")\n",
    "X_train = pd.concat([X_train, vader_hl_df, vader_body_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_str_cols(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 51)\n",
      "(49972,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD TEST SET ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25413/25413 [00:17<00:00, 1482.99it/s]\n",
      "100%|██████████| 25413/25413 [02:21<00:00, 179.89it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_hdf(\"X_test_full_allfeatures-NOLABEL.h5\", key=\"df\")\n",
    "y_test = pd.read_hdf(\"y_test_full.h5\", key=\"df\")\n",
    "\n",
    "Xy_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "y_test = Xy_test[\"Stance\"]\n",
    "X_test = Xy_test.drop(\"Stance\", axis=1)\n",
    "\n",
    "vader_hl_df = vader_polarity_scores(X_test, \"Headline\", \"hl\")\n",
    "vader_body_df = vader_polarity_scores(X_test, \"articleBody\", \"body\")\n",
    "X_test = pd.concat([X_test, vader_hl_df, vader_body_df], axis=1)\n",
    "\n",
    "del_str_cols(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = sklearn.model_selection.train_test_split(X_train, y_train, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37479, 51)\n",
      "(37479,)\n",
      "(12493, 51)\n",
      "(12493,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_count</th>\n",
       "      <th>bin_count_early</th>\n",
       "      <th>bin_count_stopless</th>\n",
       "      <th>word_overlap_features</th>\n",
       "      <th>wrf_hl_fake</th>\n",
       "      <th>wrf_hl_fraud</th>\n",
       "      <th>wrf_hl_hoax</th>\n",
       "      <th>wrf_hl_false</th>\n",
       "      <th>wrf_hl_deny</th>\n",
       "      <th>wrf_hl_denies</th>\n",
       "      <th>...</th>\n",
       "      <th>chargram_16_early_hits</th>\n",
       "      <th>chargram_16_first_hits</th>\n",
       "      <th>vader_hl_compound</th>\n",
       "      <th>vader_hl_neg</th>\n",
       "      <th>vader_hl_neu</th>\n",
       "      <th>vader_hl_pos</th>\n",
       "      <th>vader_body_compound</th>\n",
       "      <th>vader_body_neg</th>\n",
       "      <th>vader_body_neu</th>\n",
       "      <th>vader_body_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7231</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48827</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46621</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7506</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9393</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10917</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_count  bin_count_early  bin_count_stopless  word_overlap_features  \\\n",
       "7231           7                6                   5               0.057851   \n",
       "48827          6                5                   4               0.083333   \n",
       "46621          3                1                   2               0.015625   \n",
       "15590          1                1                   0               0.006494   \n",
       "10917          7                5                   3               0.015544   \n",
       "\n",
       "       wrf_hl_fake  wrf_hl_fraud  wrf_hl_hoax  wrf_hl_false  wrf_hl_deny  \\\n",
       "7231             0             0            0             0            0   \n",
       "48827            0             0            0             0            0   \n",
       "46621            0             0            0             0            0   \n",
       "15590            0             0            1             0            0   \n",
       "10917            0             0            0             0            0   \n",
       "\n",
       "       wrf_hl_denies       ...        chargram_16_early_hits  \\\n",
       "7231               0       ...                             0   \n",
       "48827              0       ...                             0   \n",
       "46621              0       ...                             0   \n",
       "15590              0       ...                             0   \n",
       "10917              0       ...                             0   \n",
       "\n",
       "       chargram_16_first_hits  vader_hl_compound  vader_hl_neg  vader_hl_neu  \\\n",
       "7231                        0             0.3400         0.000         0.789   \n",
       "48827                       0             0.0000         0.000         1.000   \n",
       "46621                       0            -0.4767         0.256         0.744   \n",
       "15590                       0            -0.9393         0.646         0.354   \n",
       "10917                       0            -0.2960         0.180         0.820   \n",
       "\n",
       "       vader_hl_pos  vader_body_compound  vader_body_neg  vader_body_neu  \\\n",
       "7231          0.211               0.8948           0.030           0.883   \n",
       "48827         0.000               0.7630           0.106           0.731   \n",
       "46621         0.000              -0.7506           0.116           0.805   \n",
       "15590         0.000               0.9618           0.040           0.843   \n",
       "10917         0.000               0.8225           0.024           0.925   \n",
       "\n",
       "       vader_body_pos  \n",
       "7231            0.087  \n",
       "48827           0.163  \n",
       "46621           0.079  \n",
       "15590           0.117  \n",
       "10917           0.051  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       36629.8190           49.68s\n",
      "         2       32775.6925           46.67s\n",
      "         3       29664.1562           47.33s\n",
      "         4       27110.3178           48.91s\n",
      "         5       25006.9279           46.48s\n",
      "         6       23246.4086           45.94s\n",
      "         7       21772.6165           44.82s\n",
      "         8       20515.7649           45.46s\n",
      "         9       19472.4843           44.17s\n",
      "        10       18553.3752           43.37s\n",
      "        20       14235.1282           38.48s\n",
      "        30       12889.4275           36.25s\n",
      "        40       12286.8561           32.89s\n",
      "        50       11925.5085           29.90s\n",
      "        60       11587.7477           27.61s\n",
      "        70       11313.9165           25.43s\n",
      "        80       11081.2357           23.20s\n",
      "        90       10875.4810           21.00s\n",
      "       100       10704.8520           18.84s\n",
      "       200        9313.2458            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              presort='auto', random_state=14128, subsample=1.0,\n",
       "              verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.65      0.26      0.37       910\n",
      "   disagree       0.50      0.06      0.11       230\n",
      "    discuss       0.69      0.86      0.77      2223\n",
      "  unrelated       0.96      0.98      0.97      9130\n",
      "\n",
      "avg / total       0.88      0.89      0.88     12493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, preds))\n",
    "# With VADER sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted accuracy: 0.8196351076078292 (4627.25 out of 5645.5)\n"
     ]
    }
   ],
   "source": [
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.46      0.17      0.25      1903\n",
      "   disagree       0.16      0.01      0.01       697\n",
      "    discuss       0.62      0.77      0.69      4464\n",
      "  unrelated       0.94      0.98      0.96     18349\n",
      "\n",
      "avg / total       0.83      0.86      0.83     25413\n",
      "\n",
      "Weighted accuracy: 0.7553910524621822 (8801.25 out of 11651.25)\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "score, max_score = score_4class(y_test, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.82      0.37      0.51      2768\n",
      "   disagree       0.92      0.20      0.33       610\n",
      "    discuss       0.73      0.88      0.80      6686\n",
      "  unrelated       0.97      0.99      0.98     27415\n",
      "\n",
      "avg / total       0.91      0.91      0.90     37479\n",
      "\n",
      "Weighted accuracy: 0.8471575711900223 (14332.0 out of 16917.75)\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_train)\n",
    "print(classification_report(y_train, preds))\n",
    "\n",
    "score, max_score = score_4class(y_train, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=8,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn.ensemble.RandomForestClassifier(n_estimators=400, n_jobs=8, random_state=42)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.76      0.33      0.46       910\n",
      "   disagree       0.84      0.11      0.20       230\n",
      "    discuss       0.72      0.87      0.79      2223\n",
      "  unrelated       0.96      0.99      0.97      9130\n",
      "\n",
      "avg / total       0.90      0.90      0.89     12493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = crf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted accuracy: 0.8332742892569303 (4704.25 out of 5645.5)\n"
     ]
    }
   ],
   "source": [
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.44      0.14      0.21      1903\n",
      "   disagree       0.00      0.00      0.00       697\n",
      "    discuss       0.62      0.76      0.68      4464\n",
      "  unrelated       0.93      0.98      0.95     18349\n",
      "\n",
      "avg / total       0.81      0.85      0.82     25413\n",
      "\n",
      "Weighted accuracy: 0.7426027250295033 (8652.25 out of 11651.25)\n"
     ]
    }
   ],
   "source": [
    "preds = crf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "score, max_score = score_4class(y_test, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       1.00      1.00      1.00      2768\n",
      "   disagree       1.00      1.00      1.00       610\n",
      "    discuss       1.00      1.00      1.00      6686\n",
      "  unrelated       1.00      1.00      1.00     27415\n",
      "\n",
      "avg / total       1.00      1.00      1.00     37479\n",
      "\n",
      "Weighted accuracy: 0.9996896750454405 (16912.5 out of 16917.75)\n"
     ]
    }
   ],
   "source": [
    "preds = crf.predict(X_train)\n",
    "print(classification_report(y_train, preds))\n",
    "\n",
    "score, max_score = score_4class(y_train, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       25260.8826           49.47s\n",
      "         2       22742.2557            1.01m\n",
      "         3       20697.6291           55.47s\n",
      "         4       19029.7974           58.47s\n",
      "         5       17616.3467           57.94s\n",
      "         6       16450.4047           57.81s\n",
      "         7       15480.2821           57.11s\n",
      "         8       14669.1370           58.96s\n",
      "         9       13974.5050           56.98s\n",
      "        10       13398.7380           57.72s\n",
      "        20       10582.2960           52.74s\n",
      "        30        9653.6478           52.48s\n",
      "        40        9170.9300           45.37s\n",
      "        50        8811.0736           38.89s\n",
      "        60        8523.0586           34.80s\n",
      "        70        8267.4833           31.30s\n",
      "        80        8027.8552           29.27s\n",
      "        90        7842.8616           27.78s\n",
      "       100        7633.8265           25.73s\n",
      "       200        6325.2492            0.00s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.82      0.51      0.63      1903\n",
      "   disagree       0.86      0.33      0.48       697\n",
      "    discuss       0.77      0.87      0.82      4464\n",
      "  unrelated       0.96      0.99      0.97     18349\n",
      "\n",
      "avg / total       0.91      0.91      0.91     25413\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.38      0.21      0.27       910\n",
      "   disagree       0.05      0.01      0.01       230\n",
      "    discuss       0.64      0.76      0.69      2223\n",
      "  unrelated       0.95      0.97      0.96      9130\n",
      "\n",
      "avg / total       0.84      0.86      0.85     12493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_test, y_test)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "preds = clf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted accuracy: 0.7736692941280666 (4367.75 out of 5645.5)\n"
     ]
    }
   ],
   "source": [
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader_body_compound: 0.11721836353874318\n",
      "bin_count_stopless: 0.11698913079580249\n",
      "word_overlap_features: 0.10004906933014432\n",
      "vader_body_neg: 0.07261528319554078\n",
      "vader_hl_compound: 0.07131559825952277\n",
      "vader_body_neu: 0.06663446208692016\n",
      "vader_body_pos: 0.05604037760630517\n",
      "bin_count: 0.04927385882253784\n",
      "ngram_2_hits: 0.04328924411982605\n",
      "bin_count_early: 0.042782794859227015\n",
      "vader_hl_neg: 0.03902429051737139\n",
      "ngram_2_early_hits: 0.03182416788213388\n",
      "chargram_2_hits: 0.03181427032901217\n",
      "vader_hl_pos: 0.030651339602869768\n",
      "vader_hl_neu: 0.026352595129833744\n",
      "polar_body: 0.01576324740683835\n",
      "chargram_2_early_hits: 0.013416901830357202\n",
      "wrf_hl_fake: 0.011936043545094177\n",
      "chargram_4_hits: 0.008322823696756528\n",
      "wrf_hl_not: 0.008305521185698626\n",
      "chargram_2_first_hits: 0.008104173190856812\n",
      "polar_hl: 0.006598122764430021\n",
      "ngram_3_early_hits: 0.004872491778207736\n",
      "wrf_hl_denies: 0.004185392536388371\n",
      "ngram_3_hits: 0.004137805049519469\n",
      "wrf_hl_hoax: 0.0034690016492651093\n",
      "wrf_hl_false: 0.0031385593689231407\n",
      "ngram_4_hits: 0.0029627624441261624\n",
      "ngram_6_hits: 0.0025766012115830783\n",
      "ngram_4_early_hits: 0.0018751189460210456\n",
      "ngram_5_hits: 0.0013224452672026827\n",
      "wrf_hl_despite: 0.0011102682400969438\n",
      "ngram_6_early_hits: 0.0008053209468312188\n",
      "wrf_hl_deny: 0.0007473981774590126\n",
      "ngram_5_early_hits: 0.000250428882143567\n",
      "wrf_hl_doubt: 0.0002247258064101739\n",
      "chargram_8_hits: 0.0\n",
      "chargram_16_hits: 0.0\n",
      "chargram_4_first_hits: 0.0\n",
      "chargram_4_early_hits: 0.0\n",
      "chargram_8_first_hits: 0.0\n",
      "wrf_hl_fraud: 0.0\n",
      "chargram_8_early_hits: 0.0\n",
      "wrf_hl_retract: 0.0\n",
      "wrf_hl_pranks: 0.0\n",
      "chargram_16_early_hits: 0.0\n",
      "wrf_hl_nope: 0.0\n",
      "wrf_hl_doubts: 0.0\n",
      "wrf_hl_bogus: 0.0\n",
      "wrf_hl_debunk: 0.0\n",
      "chargram_16_first_hits: 0.0\n"
     ]
    }
   ],
   "source": [
    "feat_imp = clf.feature_importances_\n",
    "indices = np.argsort(feat_imp)[::-1]\n",
    "for ii in indices:\n",
    "    print(X_train.columns[ii]+\": \"+str(feat_imp[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn.ensemble.RandomForestClassifier(n_estimators=200, n_jobs=8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = crf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-class problem:\n",
    "# By guessing most common category (unrelated), we would achieve approx. 73% accuracy. The baseline model achieves 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3 class problem filter out unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37479, 52)\n"
     ]
    }
   ],
   "source": [
    "Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "print(Xy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10064, 52)\n"
     ]
    }
   ],
   "source": [
    "Xy_train = Xy_train[Xy_train[\"Stance\"] != \"unrelated\"]\n",
    "print(Xy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10064, 51)\n",
      "(10064,)\n"
     ]
    }
   ],
   "source": [
    "y_train = Xy_train[\"Stance\"]\n",
    "X_train = Xy_train.drop(\"Stance\", axis=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3363, 51)\n",
      "(3363,)\n"
     ]
    }
   ],
   "source": [
    "Xy_dev = pd.concat([X_dev, y_dev], axis=1)\n",
    "Xy_dev = Xy_dev[Xy_dev[\"Stance\"] != \"unrelated\"]\n",
    "y_dev = Xy_dev[\"Stance\"]\n",
    "X_dev = Xy_dev.drop(\"Stance\", axis=1)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7064, 51)\n",
      "(7064,)\n"
     ]
    }
   ],
   "source": [
    "Xy_test = pd.concat([X_test, y_test], axis=1)\n",
    "Xy_test = Xy_test[Xy_test[\"Stance\"] != \"unrelated\"]\n",
    "y_test = Xy_test[\"Stance\"]\n",
    "X_test = Xy_test.drop(\"Stance\", axis=1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        9167.3007           11.43s\n",
      "         2        8898.4178           11.58s\n",
      "         3        8672.0611           12.95s\n",
      "         4        8474.9856           12.21s\n",
      "         5        8306.5268           11.85s\n",
      "         6        8162.5121           11.28s\n",
      "         7        8030.3965           10.86s\n",
      "         8        7916.1301           10.53s\n",
      "         9        7824.5040           10.37s\n",
      "        10        7741.8155           10.40s\n",
      "        20        7246.2035            9.40s\n",
      "        30        7016.5002           10.19s\n",
      "        40        6839.6531            9.62s\n",
      "        50        6693.1649            8.75s\n",
      "        60        6561.6648            7.72s\n",
      "        70        6444.5214            6.93s\n",
      "        80        6327.9966            6.24s\n",
      "        90        6221.2381            5.58s\n",
      "       100        6117.6191            5.05s\n",
      "       200        5349.9633            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              presort='auto', random_state=14128, subsample=1.0,\n",
       "              verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.87      0.43      0.58      2768\n",
      "   disagree       0.92      0.24      0.38       610\n",
      "    discuss       0.77      0.98      0.86      6686\n",
      "\n",
      "avg / total       0.81      0.79      0.75     10064\n",
      "\n",
      "Weighted accuracy: 0.8393282988871225 (8447.0 out of 10064.0)\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_train)\n",
    "print(classification_report(y_train, preds))\n",
    "\n",
    "score, max_score = score_4class(y_train, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.70      0.31      0.43       910\n",
      "   disagree       0.69      0.12      0.20       230\n",
      "    discuss       0.73      0.96      0.83      2223\n",
      "\n",
      "avg / total       0.72      0.73      0.68      3363\n",
      "\n",
      "Weighted accuracy: 0.7966101694915254 (2679.0 out of 3363.0)\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))\n",
    "\n",
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.42      0.21      0.28      1903\n",
      "   disagree       0.27      0.03      0.05       697\n",
      "    discuss       0.66      0.90      0.76      4464\n",
      "\n",
      "avg / total       0.56      0.62      0.56      7064\n",
      "\n",
      "Weighted accuracy: 0.7180067950169875 (5072.0 out of 7064.0)\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "score, max_score = score_4class(y_test, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 391,   18, 1494],\n",
       "       [ 117,   19,  561],\n",
       "       [ 432,   34, 3998]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds, labels=[\"agree\", \"disagree\", \"discuss\"], sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
