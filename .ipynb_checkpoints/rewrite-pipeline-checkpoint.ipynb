{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "import re\n",
    "import nltk\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from functools import partial\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./fnc-1/\"\n",
    "bodies_train = pd.read_csv(os.path.join(data_path, \"train_bodies.csv\"), header=0)\n",
    "headlines_train = pd.read_csv(os.path.join(data_path, \"train_stances.csv\"), header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1683, 2)\n",
      "(49972, 3)\n",
      "(904, 2)\n",
      "(25413, 3)\n"
     ]
    }
   ],
   "source": [
    "print(bodies_train.shape)\n",
    "print(headlines_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodies_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>Seth Rogen to Play Apple’s Steve Wozniak</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Mexico police find mass grave near site 43 stu...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>Mexico Says Missing Students Not Found In Firs...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>New iOS 8 bug can delete all of your iCloud do...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>Return of the Mac: Seth Rogen in talks to star...</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>Seth Rogen Is Woz</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>Mexico finds 4 more graves at site of suspecte...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>Are missing students in mass graves found near...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>Mexico prosecutor: Students not in 1st mass gr...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10036</th>\n",
       "      <td>Lady on FB: I'm 41, Intersex, and Fucked Micha...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10780</th>\n",
       "      <td>Catholic Priest Claims God Is Female After Cli...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11687</th>\n",
       "      <td>Isis claims US hostage Kayla Mueller killed in...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11864</th>\n",
       "      <td>Gold Apple Watch Edition price? Speculators sa...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15746</th>\n",
       "      <td>Mexican students not among bodies found in mas...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21620</th>\n",
       "      <td>Steve Jobs Biopic Eyes Seth Rogen to Play Appl...</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21712</th>\n",
       "      <td>Missing Mexico students not among 28 bodies fo...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21928</th>\n",
       "      <td>Taylor Lianne Chandler: Everything you need to...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100</th>\n",
       "      <td>Mexican cartel leader kills self; bodies in gr...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25006</th>\n",
       "      <td>Bodies In Mexico Mass Grave Apparently Not Tho...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25492</th>\n",
       "      <td>Seth Rogen Eyed to Play Apple's Steve Wozniak ...</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25616</th>\n",
       "      <td>Mexican investigators fear mass grave might ho...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26260</th>\n",
       "      <td>6 hidden mass graves may hold missing Mexican ...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26398</th>\n",
       "      <td>Mass grave found after 40 students disappear i...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27200</th>\n",
       "      <td>Mexico Student Massacre Update: More Graves Di...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29988</th>\n",
       "      <td>Seth Rogen To Play Steve Wozniak In Steve Jobs...</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33683</th>\n",
       "      <td>Taylor Lianne Chandler: Michael Phelps' Cougar...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37095</th>\n",
       "      <td>Newly Discovered Mass Grave Linked to Missing ...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38326</th>\n",
       "      <td>Michael Phelps' self-proclaimed 'girlfriend', ...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41035</th>\n",
       "      <td>Missing Mexican students 'not found in mass gr...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42776</th>\n",
       "      <td>Mexico checks if 43 missing students in mass g...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43897</th>\n",
       "      <td>Rumor: Seth Rogen to Appear as Woz in Sony's S...</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>This Powerful Cartoon About The Charlie Hebdo ...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45222</th>\n",
       "      <td>Mexico Says Students Not Among Dead in Mass Grave</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45579</th>\n",
       "      <td>Mexico hit by student massacre: At least 17 an...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46530</th>\n",
       "      <td>Seth Rogen to Star as Steve Wozniak in Sony's ...</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47712</th>\n",
       "      <td>Michael Phelps’ alleged girlfriend says she wa...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47850</th>\n",
       "      <td>Mass Graves Found In Mexico, Near Place Where ...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48228</th>\n",
       "      <td>A Mass Grave Points to a Student Massacre in M...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Headline  Body ID     Stance\n",
       "0      Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1787            Seth Rogen to Play Apple’s Steve Wozniak      712    discuss\n",
       "3974   Mexico police find mass grave near site 43 stu...      712  unrelated\n",
       "4936   Mexico Says Missing Students Not Found In Firs...      712  unrelated\n",
       "5210   New iOS 8 bug can delete all of your iCloud do...      712  unrelated\n",
       "5863   Return of the Mac: Seth Rogen in talks to star...      712    discuss\n",
       "6199                                   Seth Rogen Is Woz      712    discuss\n",
       "6756   Mexico finds 4 more graves at site of suspecte...      712  unrelated\n",
       "7526   Are missing students in mass graves found near...      712  unrelated\n",
       "9003   Mexico prosecutor: Students not in 1st mass gr...      712  unrelated\n",
       "10036  Lady on FB: I'm 41, Intersex, and Fucked Micha...      712  unrelated\n",
       "10780  Catholic Priest Claims God Is Female After Cli...      712  unrelated\n",
       "11687  Isis claims US hostage Kayla Mueller killed in...      712  unrelated\n",
       "11864  Gold Apple Watch Edition price? Speculators sa...      712  unrelated\n",
       "15746  Mexican students not among bodies found in mas...      712  unrelated\n",
       "21620  Steve Jobs Biopic Eyes Seth Rogen to Play Appl...      712    discuss\n",
       "21712  Missing Mexico students not among 28 bodies fo...      712  unrelated\n",
       "21928  Taylor Lianne Chandler: Everything you need to...      712  unrelated\n",
       "22100  Mexican cartel leader kills self; bodies in gr...      712  unrelated\n",
       "25006  Bodies In Mexico Mass Grave Apparently Not Tho...      712  unrelated\n",
       "25492  Seth Rogen Eyed to Play Apple's Steve Wozniak ...      712    discuss\n",
       "25616  Mexican investigators fear mass grave might ho...      712  unrelated\n",
       "26260  6 hidden mass graves may hold missing Mexican ...      712  unrelated\n",
       "26398  Mass grave found after 40 students disappear i...      712  unrelated\n",
       "27200  Mexico Student Massacre Update: More Graves Di...      712  unrelated\n",
       "29988  Seth Rogen To Play Steve Wozniak In Steve Jobs...      712    discuss\n",
       "33683  Taylor Lianne Chandler: Michael Phelps' Cougar...      712  unrelated\n",
       "37095  Newly Discovered Mass Grave Linked to Missing ...      712  unrelated\n",
       "38326  Michael Phelps' self-proclaimed 'girlfriend', ...      712  unrelated\n",
       "41035  Missing Mexican students 'not found in mass gr...      712  unrelated\n",
       "42776  Mexico checks if 43 missing students in mass g...      712  unrelated\n",
       "43897  Rumor: Seth Rogen to Appear as Woz in Sony's S...      712    discuss\n",
       "44978  This Powerful Cartoon About The Charlie Hebdo ...      712  unrelated\n",
       "45222  Mexico Says Students Not Among Dead in Mass Grave      712  unrelated\n",
       "45579  Mexico hit by student massacre: At least 17 an...      712  unrelated\n",
       "46530  Seth Rogen to Star as Steve Wozniak in Sony's ...      712    discuss\n",
       "47712  Michael Phelps’ alleged girlfriend says she wa...      712  unrelated\n",
       "47850  Mass Graves Found In Mexico, Near Place Where ...      712  unrelated\n",
       "48228  A Mass Grave Points to a Student Massacre in M...      712  unrelated"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_train[headlines_train[\"Body ID\"] == 712]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = headlines_train.merge(bodies_train, on=[\"Body ID\"], how=\"left\")\n",
    "X_train = temp[[\"Headline\", \"articleBody\"]] # TODO include stance here and re-run\n",
    "y_train = temp[\"Stance\"]\n",
    "assert X_train.shape[0] == y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out y_train already\n",
    "y_train.to_hdf('y_train_full.h5','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object no longer used\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY LIMIT JUST FOR TESTING TODO REMOVE\n",
    "#X_train = X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## START BASELINE FEATURE RE-WRITE\n",
    "_wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def normalize_word(w):\n",
    "    return _wnl.lemmatize(w).lower()\n",
    "\n",
    "\n",
    "def get_tokenized_lemmas(s):\n",
    "    return [normalize_word(t) for t in nltk.word_tokenize(s)]\n",
    "\n",
    "\n",
    "def clean(s):\n",
    "    # Cleans a string: Lowercasing, trimming, removing non-alphanumeric\n",
    "    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()\n",
    "\n",
    "\n",
    "def remove_stopwords(l):\n",
    "    # Removes stopwords from a list of tokens\n",
    "    return [w for w in l if w not in sklearn.feature_extraction.text.ENGLISH_STOP_WORDS]\n",
    "\n",
    "def word_overlap_features_2(df):\n",
    "    clean_headline = set(df[\"___clean_headline_tokenized_lemmas\"])\n",
    "    clean_body = set(df[\"___clean_body_tokenized_lemmas\"])\n",
    "    feature = len(clean_headline & clean_body)/float(len(clean_headline | clean_body))\n",
    "    return feature\n",
    "\n",
    "def refuting_features_adder(df):\n",
    "    # Returns 1/0 if each of these words is present in headline\n",
    "    _refuting_words = [\n",
    "        'fake',\n",
    "        'fraud',\n",
    "        'hoax',\n",
    "        'false',\n",
    "        'deny', 'denies',\n",
    "        # 'refute',\n",
    "        'not',\n",
    "        'despite',\n",
    "        'nope',\n",
    "        'doubt', 'doubts',\n",
    "        'bogus',\n",
    "        'debunk',\n",
    "        'pranks',\n",
    "        'retract'\n",
    "    ]\n",
    "    clean_headline = df[\"___clean_headline_tokenized_lemmas\"]\n",
    "    features = clean_headline.apply(lambda hl: pd.Series([1 if word in hl else 0 for word in _refuting_words]))\n",
    "    features.columns = [\"wrf_hl_\"+ref_word for ref_word in _refuting_words]\n",
    "    return pd.concat([df, features], axis=1)\n",
    "\n",
    "\n",
    "def polarity_features_adder(df):\n",
    "    _refuting_words = [\n",
    "        'fake',\n",
    "        'fraud',\n",
    "        'hoax',\n",
    "        'false',\n",
    "        'deny', 'denies',\n",
    "        'not',\n",
    "        'despite',\n",
    "        'nope',\n",
    "        'doubt', 'doubts',\n",
    "        'bogus',\n",
    "        'debunk',\n",
    "        'pranks',\n",
    "        'retract'\n",
    "    ]\n",
    "    def calculate_polarity(tokens):\n",
    "        return sum([t in _refuting_words for t in tokens]) % 2\n",
    "    \n",
    "    clean_headline = df[\"___clean_headline_tokenized_lemmas\"]\n",
    "    clean_body = df[\"___clean_body_tokenized_lemmas\"]\n",
    "    \n",
    "    \n",
    "    headline_polarity = pd.DataFrame(clean_headline.apply(calculate_polarity))\n",
    "    headline_polarity.columns = [\"polar_hl\"]\n",
    "    \n",
    "    body_polarity = pd.DataFrame(clean_body.apply(calculate_polarity))\n",
    "    body_polarity.columns = [\"polar_body\"]\n",
    "    \n",
    "    df = pd.concat([df, headline_polarity, body_polarity], axis=1)\n",
    "    return df\n",
    "\n",
    "## START hand_features\n",
    "def binary_co_occurrence(row):\n",
    "    # Count how many times a token in the title\n",
    "    # appears in the body text.\n",
    "    bin_count = 0\n",
    "    bin_count_early = 0\n",
    "    for headline_token in row[\"___clean_headline\"].split(\" \"):\n",
    "        if headline_token in row[\"___clean_body\"]:\n",
    "            bin_count += 1\n",
    "        if headline_token in row[\"___clean_body\"][:255]:\n",
    "            bin_count_early += 1\n",
    "    return pd.Series((bin_count, bin_count_early))\n",
    "\n",
    "def binary_co_occurence_stops(row):\n",
    "        # Count how many times a token in the title\n",
    "        # appears in the body text. Stopwords in the title\n",
    "        # are ignored.\n",
    "        bin_count_stopless = 0\n",
    "        #bin_count_early = 0\n",
    "        for headline_token in remove_stopwords(row[\"___clean_headline\"].split(\" \")):\n",
    "            if headline_token in row[\"___clean_body\"]:\n",
    "                bin_count_stopless += 1\n",
    "                #bin_count_early += 1 # TODO why are these values the same in the baseline??? bizarre... deleting\n",
    "        return bin_count_stopless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chargrams(input, n):\n",
    "    output = []\n",
    "    for i in range(len(input) - n + 1):\n",
    "        output.append(input[i:i + n])\n",
    "    return output\n",
    "\n",
    "def ngrams(input, n):\n",
    "    input = input.split(' ')\n",
    "    output = []\n",
    "    for i in range(len(input) - n + 1):\n",
    "        output.append(input[i:i + n])\n",
    "    return output\n",
    "\n",
    "def append_chargrams(row, size=None):\n",
    "    grams = [' '.join(x) for x in chargrams(\" \".join(remove_stopwords(row[\"___clean_headline\"].split())), size)]\n",
    "    grams_hits = 0\n",
    "    grams_early_hits = 0\n",
    "    grams_first_hits = 0\n",
    "    for gram in grams:\n",
    "        if gram in row[\"___clean_body\"]:\n",
    "            grams_hits += 1\n",
    "        if gram in row[\"___clean_body\"][:255]:\n",
    "            grams_early_hits += 1\n",
    "        if gram in row[\"___clean_body\"][:100]:\n",
    "            grams_first_hits += 1\n",
    "    return pd.Series((grams_hits, grams_early_hits, grams_first_hits))\n",
    "\n",
    "def append_ngrams(row, size=None):\n",
    "    grams = [' '.join(x) for x in ngrams(row[\"___clean_headline\"], size)]\n",
    "    grams_hits = 0\n",
    "    grams_early_hits = 0\n",
    "    for gram in grams:\n",
    "        if gram in row[\"___clean_body\"]:\n",
    "            grams_hits += 1\n",
    "        if gram in row[\"___clean_body\"][:255]:\n",
    "            grams_early_hits += 1\n",
    "    return pd.Series((grams_hits, grams_early_hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding cached columns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gui/anaconda3/envs/nlu4/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/gui/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-93353551abb5>\u001b[0m in \u001b[0;36mgen_all_features\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adding cached columns...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0madd_cached_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adding co-occurrences...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-93353551abb5>\u001b[0m in \u001b[0;36madd_cached_columns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"___clean_body\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"articleBody\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_helper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"___clean_body_tokenized_lemmas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"___clean_body\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_tokenized_lemmas_helper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-93353551abb5>\u001b[0m in \u001b[0;36mparallelize\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu4/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu4/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu4/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Multiprocessing code copied from: http://blog.adeel.io/2016/11/06/parallelize-pandas-map-or-apply/\n",
    "cores = cpu_count() #Number of CPU cores on your system\n",
    "partitions = cores #Define as many partitions as you want\n",
    "def parallelize(data, func):\n",
    "    data_split = np.array_split(data, partitions)\n",
    "    pool = Pool(cores)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "def word_overlap_features_parallel_helper(df):\n",
    "        return df.apply(lambda row: word_overlap_features_2(row), axis=1)\n",
    "def clean_helper(df):\n",
    "        return df.apply(clean)\n",
    "def get_tokenized_lemmas_helper(df):\n",
    "        return df.apply(get_tokenized_lemmas)\n",
    "def chargram_helper(df, input_size=None):\n",
    "    return df.apply(lambda row: append_chargrams(row, input_size), axis=1)\n",
    "def ngram_helper(df, input_size=None):\n",
    "    return df.apply(lambda row: append_ngrams(row, input_size), axis=1)\n",
    "\n",
    "def add_cached_columns(df):\n",
    "    # column names starting with 3 underscores (___....) are cached intermediate\n",
    "    # values only used to speed-up feature computation\n",
    "\n",
    "    df[\"___clean_headline\"] = parallelize(df[\"Headline\"], clean_helper)\n",
    "    df[\"___clean_headline_tokenized_lemmas\"] = parallelize(df[\"___clean_headline\"], get_tokenized_lemmas_helper)\n",
    "    \n",
    "    df[\"___clean_body\"] = parallelize(df[\"articleBody\"], clean_helper)\n",
    "    df[\"___clean_body_tokenized_lemmas\"] = parallelize(df[\"___clean_body\"], get_tokenized_lemmas_helper)\n",
    "    \n",
    "\n",
    "def gen_all_features(df):\n",
    "    print(\"Adding cached columns...\")\n",
    "    add_cached_columns(X_train)\n",
    "    \n",
    "    print(\"Adding co-occurrences...\")\n",
    "    co_occurrences = df.apply(binary_co_occurrence, axis=1)\n",
    "    co_occurrences.columns = [\"bin_count\", \"bin_count_early\"]\n",
    "    df = pd.concat([df, co_occurrences], axis=1)\n",
    "    df[\"bin_count_stopless\"] = df.apply(binary_co_occurence_stops, axis=1)\n",
    "    \n",
    "    # Note: As far as I can tell, the SettingWithCopy warning the following call raises\n",
    "    # is just a false positive. Usage is actually ok.\n",
    "    print(\"Adding word_overlap_features....\")\n",
    "    df[\"word_overlap_features\"] = parallelize(df, word_overlap_features_parallel_helper)\n",
    "    \n",
    "    print(\"Adding refuting_features....\")\n",
    "    df = refuting_features_adder(df)\n",
    "    \n",
    "    print(\"Adding polarity_features....\")\n",
    "    df = polarity_features_adder(df)\n",
    "    \n",
    "    print(\"Adding ngrams...\")\n",
    "    ngram_sizes = [2, 3, 4, 5, 6]\n",
    "    for ngram_size in tqdm_notebook(ngram_sizes, total=len(ngram_sizes)):\n",
    "        helper_fn = partial(ngram_helper, input_size=ngram_size)\n",
    "        temp = parallelize(df, helper_fn)\n",
    "        temp.columns = [\"ngram_\"+str(ngram_size)+\"_hits\", \"ngram_\"+str(ngram_size)+\"_early_hits\"]\n",
    "        df = pd.concat([df, temp], axis=1)\n",
    "    \n",
    "    print(\"Adding chargrams...\")\n",
    "    chargram_sizes = [2, 8, 4, 16]\n",
    "    for chargram_size in tqdm_notebook(chargram_sizes, total=len(chargram_sizes)):\n",
    "        helper_fn = partial(chargram_helper, input_size=chargram_size)\n",
    "        temp = parallelize(df, helper_fn)\n",
    "        temp.columns = [\"chargram_\"+str(chargram_size)+\"_hits\", \"chargram_\"+str(chargram_size)+\"_early_hits\", \"chargram_\"+str(chargram_size)+\"_first_hits\"]\n",
    "        df = pd.concat([df, temp], axis=1)\n",
    "    \n",
    "    return df\n",
    "%time X_train = gen_all_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X_test = gen_all_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>___clean_headline</th>\n",
       "      <th>___clean_headline_tokenized_lemmas</th>\n",
       "      <th>___clean_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\n\\n...</td>\n",
       "      <td>police find mass graves with at least 15 bodie...</td>\n",
       "      <td>[police, find, mass, graf, with, at, least, 15...</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>[hundred, of, palestinian, flee, flood, in, ga...</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>[christian, bale, pass, on, role, of, steve, j...</td>\n",
       "      <td>30 year old moscow resident was hospitalized w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "      <td>hbo and apple in talks for 15 month apple tv s...</td>\n",
       "      <td>[hbo, and, apple, in, talk, for, 15, month, ap...</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>[spider, burrowed, through, tourist, s, stomac...</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  Police find mass graves with at least '15 bodi...   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...   \n",
       "4  Spider burrowed through tourist's stomach and ...   \n",
       "\n",
       "                                         articleBody  \\\n",
       "0  Danny Boyle is directing the untitled film\\n\\n...   \n",
       "1  Hundreds of Palestinians were evacuated from t...   \n",
       "2  30-year-old Moscow resident was hospitalized w...   \n",
       "3  (Reuters) - A Canadian soldier was shot at the...   \n",
       "4  Fear not arachnophobes, the story of Bunbury's...   \n",
       "\n",
       "                                   ___clean_headline  \\\n",
       "0  police find mass graves with at least 15 bodie...   \n",
       "1  hundreds of palestinians flee floods in gaza a...   \n",
       "2  christian bale passes on role of steve jobs ac...   \n",
       "3  hbo and apple in talks for 15 month apple tv s...   \n",
       "4  spider burrowed through tourist s stomach and ...   \n",
       "\n",
       "                  ___clean_headline_tokenized_lemmas  \\\n",
       "0  [police, find, mass, graf, with, at, least, 15...   \n",
       "1  [hundred, of, palestinian, flee, flood, in, ga...   \n",
       "2  [christian, bale, pass, on, role, of, steve, j...   \n",
       "3  [hbo, and, apple, in, talk, for, 15, month, ap...   \n",
       "4  [spider, burrowed, through, tourist, s, stomac...   \n",
       "\n",
       "                                       ___clean_body  \n",
       "0  danny boyle is directing the untitled film set...  \n",
       "1  hundreds of palestinians were evacuated from t...  \n",
       "2  30 year old moscow resident was hospitalized w...  \n",
       "3  reuters a canadian soldier was shot at the can...  \n",
       "4  fear not arachnophobes the story of bunbury s ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gui/anaconda3/envs/nlu4/lib/python3.6/site-packages/pandas/core/generic.py:1993: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['Headline', 'articleBody', '___clean_headline', '___clean_headline_tokenized_lemmas', '___clean_body']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train.to_hdf('X_train_full_allfeatures.h5','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOW GENERATE FEATURES FOR TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./fnc-1/\"\n",
    "bodies_test = pd.read_csv(os.path.join(data_path, \"competition_test_bodies.csv\"), header=0)\n",
    "headlines_test = pd.read_csv(os.path.join(data_path, \"competition_test_stances.csv\"), header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(904, 2)\n",
      "(25413, 3)\n"
     ]
    }
   ],
   "source": [
    "print(bodies_test.shape)\n",
    "print(headlines_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A bereaved Afghan mother took revenge on the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CNBC is reporting Tesla has chosen Nevada as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A 4-inch version of the iPhone 6 is said to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>GR editor’s Note\\n\\nThere are no reports in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        1  Al-Sisi has denied Israeli reports stating tha...\n",
       "1        2  A bereaved Afghan mother took revenge on the T...\n",
       "2        3  CNBC is reporting Tesla has chosen Nevada as t...\n",
       "3       12  A 4-inch version of the iPhone 6 is said to be...\n",
       "4       19  GR editor’s Note\\n\\nThere are no reports in th..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodies_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ferguson riots: Pregnant woman loses eye after...</td>\n",
       "      <td>2008</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crazy Conservatives Are Sure a Gitmo Detainee ...</td>\n",
       "      <td>1550</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Russian Guy Says His Justin Bieber Ringtone ...</td>\n",
       "      <td>2</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zombie Cat: Buried Kitty Believed Dead, Meows ...</td>\n",
       "      <td>1793</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina's President Adopts Boy to End Werewo...</td>\n",
       "      <td>37</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Ferguson riots: Pregnant woman loses eye after...     2008  unrelated\n",
       "1  Crazy Conservatives Are Sure a Gitmo Detainee ...     1550  unrelated\n",
       "2  A Russian Guy Says His Justin Bieber Ringtone ...        2  unrelated\n",
       "3  Zombie Cat: Buried Kitty Believed Dead, Meows ...     1793  unrelated\n",
       "4  Argentina's President Adopts Boy to End Werewo...       37  unrelated"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = headlines_test.merge(bodies_test, on=[\"Body ID\"], how=\"left\")\n",
    "X_test = temp[[\"Headline\", \"articleBody\"]] # TODO include stance here and re-run\n",
    "y_test = temp[\"Stance\"]\n",
    "assert X_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_hdf('y_test_full.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
