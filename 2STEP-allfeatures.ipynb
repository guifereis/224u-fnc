{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "import re\n",
    "import nltk\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from functools import partial\n",
    "import ipywidgets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from rewrite.scorer import score_4class\n",
    "import utils # utils from CS224U\n",
    "from scipy.spatial import distance\n",
    "import random\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_str_cols(df): # df should be X, e.g. X_train or X_dev\n",
    "    del df[\"articleBody\"]\n",
    "    del df[\"Headline\"]\n",
    "    for col_name in df.columns:\n",
    "        if \"___\" == col_name[0:3]:\n",
    "            del df[col_name]\n",
    "            \n",
    "def print_reports(preds, actual):\n",
    "    print(classification_report(actual, preds))\n",
    "    score, max_score = score_4class(actual, preds)\n",
    "    print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoModel:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        #self.make_other_sets()\n",
    "        \n",
    "    def make_other_sets(self):\n",
    "        Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "        Xy_train, Xy_dev = sklearn.model_selection.train_test_split(Xy_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "        \n",
    "        Xy_train_1 = Xy_train.copy()\n",
    "        Xy_train_1.loc[Xy_train_1[\"Stance\"] != \"unrelated\", 'Stance'] = \"related\"\n",
    "        self.y_train_1 = Xy_train_1[\"Stance\"]\n",
    "        self.X_train_1 = Xy_train_1.drop(\"Stance\", axis=1)\n",
    "        \n",
    "        Xy_dev_1 = Xy_dev.copy()\n",
    "        Xy_dev_1.loc[Xy_dev_1[\"Stance\"] != \"unrelated\", 'Stance'] = \"related\"\n",
    "        self.y_dev_1 = Xy_dev_1[\"Stance\"]\n",
    "        self.X_dev_1 = Xy_dev_1.drop(\"Stance\", axis=1)\n",
    "        \n",
    "        Xy_train_2 = Xy_train[Xy_train[\"Stance\"] != \"unrelated\"]\n",
    "        self.y_train_2 = Xy_train_2[\"Stance\"]\n",
    "        self.X_train_2 = Xy_train_2.drop(\"Stance\", axis=1)\n",
    "\n",
    "        Xy_dev_2 = Xy_dev[Xy_dev[\"Stance\"] != \"unrelated\"]\n",
    "        self.y_dev_2 = Xy_dev_2[\"Stance\"]\n",
    "        self.X_dev_2 = Xy_dev_2.drop(\"Stance\", axis=1)\n",
    "        \n",
    "        del_str_cols(self.X_train_1)\n",
    "        del_str_cols(self.X_dev_1)\n",
    "        del_str_cols(self.X_train_2)\n",
    "        del_str_cols(self.X_dev_2)\n",
    "        \n",
    "        return Xy_train.drop(\"Stance\", axis=1), Xy_train[\"Stance\"], Xy_dev.drop(\"Stance\", axis=1), Xy_dev[\"Stance\"]\n",
    "        \n",
    "    def fit(self):\n",
    "        ## CLASSIFIER 1 - RELATED/UNRELATED\n",
    "        self.mod1 = GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True)\n",
    "        self.mod1.fit(self.X_train_1, self.y_train_1)\n",
    "        \n",
    "        ## CLASSIFIER 2 - 3-class\n",
    "        self.mod2 = GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True)\n",
    "        self.mod2.fit(self.X_train_2, self.y_train_2)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        #if X is None:\n",
    "        #    X = self.X_dev_1\n",
    "        del_str_cols(X)\n",
    "        preds_1 = self.mod1.predict(X)\n",
    "        preds_2 = self.mod2.predict(X) # note X_dev_1\n",
    "        \n",
    "        new_preds = preds_1.copy()\n",
    "        for ii in range(preds_1.shape[0]):\n",
    "            if preds_1[ii] == \"related\":\n",
    "                new_preds[ii] = preds_2[ii]\n",
    "            else:\n",
    "                new_preds[ii] = \"unrelated\"\n",
    "        return new_preds\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_hdf(\"X_train_full_allfeatures-NOLABEL.h5\", key=\"df\")\n",
    "y_train = pd.read_hdf(\"y_train_full.h5\", key=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm = TwoModel(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_dev, y_dev = tsm.make_other_sets()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0244           15.78s\n",
      "         2           0.9193           14.77s\n",
      "         3           0.8355           14.34s\n",
      "         4           0.7672           14.33s\n",
      "         5           0.7104           14.16s\n",
      "         6           0.6616           13.99s\n",
      "         7           0.6199           13.90s\n",
      "         8           0.5840           13.80s\n",
      "         9           0.5530           13.68s\n",
      "        10           0.5263           13.55s\n",
      "        20           0.3716           13.19s\n",
      "        30           0.3187           12.19s\n",
      "        40           0.2952           11.21s\n",
      "        50           0.2808           10.43s\n",
      "        60           0.2717            9.67s\n",
      "        70           0.2659            8.87s\n",
      "        80           0.2615            8.16s\n",
      "        90           0.2580            7.40s\n",
      "       100           0.2552            6.72s\n",
      "       200           0.2374            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        9849.1457           10.53s\n",
      "         2        9584.9365           10.10s\n",
      "         3        9366.0192           10.46s\n",
      "         4        9181.1381           11.16s\n",
      "         5        9023.9317           11.27s\n",
      "         6        8892.0544           11.08s\n",
      "         7        8778.5524           11.05s\n",
      "         8        8683.0724           10.81s\n",
      "         9        8600.7541           10.62s\n",
      "        10        8529.2769           10.75s\n",
      "        20        8152.3534           10.39s\n",
      "        30        7999.9119            9.67s\n",
      "        40        7906.9344            9.08s\n",
      "        50        7835.2957            8.45s\n",
      "        60        7773.0786            7.83s\n",
      "        70        7716.2456            7.43s\n",
      "        80        7659.0611            6.89s\n",
      "        90        7603.0776            6.40s\n",
      "       100        7558.2873            5.79s\n",
      "       200        7151.2104            0.00s\n"
     ]
    }
   ],
   "source": [
    "tsm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tsm.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unrelated', 'unrelated', 'unrelated', ..., 'unrelated',\n",
       "       'unrelated', 'unrelated'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.63      0.17      0.26       703\n",
      "   disagree       0.80      0.02      0.04       180\n",
      "    discuss       0.65      0.88      0.75      1779\n",
      "  unrelated       0.97      0.98      0.97      7333\n",
      "\n",
      "avg / total       0.88      0.89      0.87      9995\n",
      "\n",
      "Weighted accuracy: 0.8135253879094599 (3657.0 out of 4495.25)\n"
     ]
    }
   ],
   "source": [
    "print_reports(preds, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import vader\n",
    "sid = vader.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_polarity_scores(df, text_col_name, col_name_prefix):\n",
    "    pol_scores = df[text_col_name].progress_apply(lambda hl: pd.Series(sid.polarity_scores(hl)))\n",
    "    cols = pol_scores.columns\n",
    "    new_cols = []\n",
    "    for col_name in cols:\n",
    "        new_cols.append(\"vader_\"+col_name_prefix+\"_\"+col_name)\n",
    "    pol_scores.columns = new_cols\n",
    "    return pol_scores\n",
    "\n",
    "vader_hl_df = vader_polarity_scores(X_train, \"Headline\", \"hl\")\n",
    "vader_body_df = vader_polarity_scores(X_train, \"articleBody\", \"body\")\n",
    "X_train = pd.concat([X_train, vader_hl_df, vader_body_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START GLOVE AND POS TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOVE ####\n",
    "glove_dim = 200\n",
    "glove_src = os.path.join(\"GloVe\", 'glove.6B.'+str(glove_dim)+'d.txt')\n",
    "GLOVE = utils.glove2dict(glove_src)\n",
    "def text_to_mean_vec_ignore_unk(text, w2v=GLOVE, dim=glove_dim):\n",
    "    vec = np.zeros(dim)\n",
    "    num_added = 0\n",
    "    for word in text:\n",
    "        if word in w2v:\n",
    "            vec += w2v[word]\n",
    "            num_added += 1\n",
    "    if num_added > 0:\n",
    "        return vec/num_added\n",
    "    else:\n",
    "        return np.array([random.uniform(-0.5, 0.5) for i in range(glove_dim)])\n",
    "def get_glove_cos_dist_hl_body(row):\n",
    "    hl = row[\"___clean_headline_tokenized_lemmas\"]\n",
    "    body = row[\"___clean_body_tokenized_lemmas\"]\n",
    "    hl_vec = text_to_mean_vec_ignore_unk(hl)\n",
    "    body_vec = text_to_mean_vec_ignore_unk(body)\n",
    "    cosine_dist = distance.cosine(hl_vec, body_vec) # cosine() from scipy\n",
    "    return cosine_dist\n",
    "### END GLOVE CODE BLOCK\n",
    "X_train[\"hl_body_glove_\"+str(glove_dim)+\"_cos_dist\"] = X_train[[\"___clean_headline_tokenized_lemmas\", \"___clean_body_tokenized_lemmas\"]].progress_apply(get_glove_cos_dist_hl_body, axis=1)\n",
    "\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def get_verbs(text):\n",
    "    text = nltk.tokenize.word_tokenize(text)\n",
    "    verbs = [token for token, pos in nltk.pos_tag(text) if pos.startswith('VB')]\n",
    "    verbs_sentence = ' '.join(word[0] for word in verbs)\n",
    "    return verbs_sentence\n",
    " \n",
    "def get_verb_glove_cos_dist_hl_body(row):\n",
    "    hl = row[\"___clean_headline_tokenized_lemmas\"]\n",
    "    body = row[\"___clean_body_tokenized_lemmas\"]\n",
    "    \n",
    "    h1_verbs = get_verbs(h1)\n",
    "    body_verbs = get_verbs(body)\n",
    "    \n",
    "    hl_vec = text_to_mean_vec_ignore_unk(h1_verbs)\n",
    "    body_vec = text_to_mean_vec_ignore_unk(body_verbs)\n",
    "    cosine_dist = distance.cosine(hl_vec, body_vec) # cosine() from scipy\n",
    "    return cosine_dist\n",
    "\n",
    "X_train[\"hl_body_verb_glove_\"+str(glove_dim)+\"_cos_dist\"] = X_train[[\"___clean_headline_tokenized_lemmas\", \"___clean_body_tokenized_lemmas\"]].progress_apply(get_verb_glove_cos_dist_hl_body, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END GLOVE AND  POS TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_str_cols(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD TEST SET ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_hdf(\"X_test_full_allfeatures-NOLABEL.h5\", key=\"df\")\n",
    "y_test = pd.read_hdf(\"y_test_full.h5\", key=\"df\")\n",
    "\n",
    "Xy_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "y_test = Xy_test[\"Stance\"]\n",
    "X_test = Xy_test.drop(\"Stance\", axis=1)\n",
    "\n",
    "vader_hl_df = vader_polarity_scores(X_test, \"Headline\", \"hl\")\n",
    "vader_body_df = vader_polarity_scores(X_test, \"articleBody\", \"body\")\n",
    "X_test = pd.concat([X_test, vader_hl_df, vader_body_df], axis=1)\n",
    "\n",
    "X_test[\"hl_body_glove_\"+str(glove_dim)+\"_cos_dist\"] = X_test[[\"___clean_headline_tokenized_lemmas\", \"___clean_body_tokenized_lemmas\"]].progress_apply(get_glove_cos_dist_hl_body, axis=1)\n",
    "X_test[\"hl_body_verb_glove_\"+str(glove_dim)+\"_cos_dist\"] = X_test[[\"___clean_headline_tokenized_lemmas\", \"___clean_body_tokenized_lemmas\"]].progress_apply(get_verb_glove_cos_dist_hl_body, axis=1)\n",
    "\n",
    "\n",
    "del_str_cols(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_dev, preds))\n",
    "# With VADER sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "score, max_score = score_4class(y_test, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_train)\n",
    "print(classification_report(y_train, preds))\n",
    "\n",
    "score, max_score = score_4class(y_train, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn.ensemble.RandomForestClassifier(n_estimators=400, n_jobs=8, random_state=42)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = crf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = crf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "score, max_score = score_4class(y_test, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = crf.predict(X_train)\n",
    "print(classification_report(y_train, preds))\n",
    "\n",
    "score, max_score = score_4class(y_train, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_test, y_test)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "preds = clf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = clf.feature_importances_\n",
    "indices = np.argsort(feat_imp)[::-1]\n",
    "for ii in indices:\n",
    "    print(X_train.columns[ii]+\": \"+str(feat_imp[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn.ensemble.RandomForestClassifier(n_estimators=200, n_jobs=8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = crf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-class problem:\n",
    "# By guessing most common category (unrelated), we would achieve approx. 73% accuracy. The baseline model achieves 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3 class problem filter out unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "print(Xy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = Xy_train[Xy_train[\"Stance\"] != \"unrelated\"]\n",
    "print(Xy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Xy_train[\"Stance\"]\n",
    "X_train = Xy_train.drop(\"Stance\", axis=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_dev = pd.concat([X_dev, y_dev], axis=1)\n",
    "Xy_dev = Xy_dev[Xy_dev[\"Stance\"] != \"unrelated\"]\n",
    "y_dev = Xy_dev[\"Stance\"]\n",
    "X_dev = Xy_dev.drop(\"Stance\", axis=1)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_test = pd.concat([X_test, y_test], axis=1)\n",
    "Xy_test = Xy_test[Xy_test[\"Stance\"] != \"unrelated\"]\n",
    "y_test = Xy_test[\"Stance\"]\n",
    "X_test = Xy_test.drop(\"Stance\", axis=1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_train)\n",
    "print(classification_report(y_train, preds))\n",
    "\n",
    "score, max_score = score_4class(y_train, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))\n",
    "\n",
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "score, max_score = score_4class(y_test, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, preds, labels=[\"agree\", \"disagree\", \"discuss\"], sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
