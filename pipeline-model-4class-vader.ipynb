{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "import re\n",
    "import nltk\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from functools import partial\n",
    "import ipywidgets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from rewrite.scorer import score_4class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_hdf(\"X_train_full_allfeatures-NOLABEL.h5\", key=\"df\")\n",
    "y_train = pd.read_hdf(\"y_train_full.h5\", key=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    unrelated\n",
       "1        agree\n",
       "2    unrelated\n",
       "3    unrelated\n",
       "4     disagree\n",
       "Name: Stance, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>___clean_headline</th>\n",
       "      <th>___clean_headline_tokenized_lemmas</th>\n",
       "      <th>___clean_body</th>\n",
       "      <th>___clean_body_tokenized_lemmas</th>\n",
       "      <th>bin_count</th>\n",
       "      <th>bin_count_early</th>\n",
       "      <th>bin_count_stopless</th>\n",
       "      <th>word_overlap_features</th>\n",
       "      <th>...</th>\n",
       "      <th>chargram_2_first_hits</th>\n",
       "      <th>chargram_8_hits</th>\n",
       "      <th>chargram_8_early_hits</th>\n",
       "      <th>chargram_8_first_hits</th>\n",
       "      <th>chargram_4_hits</th>\n",
       "      <th>chargram_4_early_hits</th>\n",
       "      <th>chargram_4_first_hits</th>\n",
       "      <th>chargram_16_hits</th>\n",
       "      <th>chargram_16_early_hits</th>\n",
       "      <th>chargram_16_first_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\n\\n...</td>\n",
       "      <td>police find mass graves with at least 15 bodie...</td>\n",
       "      <td>[police, find, mass, graf, with, at, least, 15...</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "      <td>[danny, boyle, is, directing, the, untitled, f...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>[hundred, of, palestinian, flee, flood, in, ga...</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "      <td>[hundred, of, palestinian, were, evacuated, fr...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>[christian, bale, pass, on, role, of, steve, j...</td>\n",
       "      <td>30 year old moscow resident was hospitalized w...</td>\n",
       "      <td>[30, year, old, moscow, resident, wa, hospital...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "      <td>hbo and apple in talks for 15 month apple tv s...</td>\n",
       "      <td>[hbo, and, apple, in, talk, for, 15, month, ap...</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "      <td>[reuters, a, canadian, soldier, wa, shot, at, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>[spider, burrowed, through, tourist, s, stomac...</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "      <td>[fear, not, arachnophobes, the, story, of, bun...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032727</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  Police find mass graves with at least '15 bodi...   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...   \n",
       "4  Spider burrowed through tourist's stomach and ...   \n",
       "\n",
       "                                         articleBody  \\\n",
       "0  Danny Boyle is directing the untitled film\\n\\n...   \n",
       "1  Hundreds of Palestinians were evacuated from t...   \n",
       "2  30-year-old Moscow resident was hospitalized w...   \n",
       "3  (Reuters) - A Canadian soldier was shot at the...   \n",
       "4  Fear not arachnophobes, the story of Bunbury's...   \n",
       "\n",
       "                                   ___clean_headline  \\\n",
       "0  police find mass graves with at least 15 bodie...   \n",
       "1  hundreds of palestinians flee floods in gaza a...   \n",
       "2  christian bale passes on role of steve jobs ac...   \n",
       "3  hbo and apple in talks for 15 month apple tv s...   \n",
       "4  spider burrowed through tourist s stomach and ...   \n",
       "\n",
       "                  ___clean_headline_tokenized_lemmas  \\\n",
       "0  [police, find, mass, graf, with, at, least, 15...   \n",
       "1  [hundred, of, palestinian, flee, flood, in, ga...   \n",
       "2  [christian, bale, pass, on, role, of, steve, j...   \n",
       "3  [hbo, and, apple, in, talk, for, 15, month, ap...   \n",
       "4  [spider, burrowed, through, tourist, s, stomac...   \n",
       "\n",
       "                                       ___clean_body  \\\n",
       "0  danny boyle is directing the untitled film set...   \n",
       "1  hundreds of palestinians were evacuated from t...   \n",
       "2  30 year old moscow resident was hospitalized w...   \n",
       "3  reuters a canadian soldier was shot at the can...   \n",
       "4  fear not arachnophobes the story of bunbury s ...   \n",
       "\n",
       "                      ___clean_body_tokenized_lemmas  bin_count  \\\n",
       "0  [danny, boyle, is, directing, the, untitled, f...          2   \n",
       "1  [hundred, of, palestinian, were, evacuated, fr...         10   \n",
       "2  [30, year, old, moscow, resident, wa, hospital...          5   \n",
       "3  [reuters, a, canadian, soldier, wa, shot, at, ...          3   \n",
       "4  [fear, not, arachnophobes, the, story, of, bun...          9   \n",
       "\n",
       "   bin_count_early  bin_count_stopless  word_overlap_features  \\\n",
       "0                0                   0               0.014085   \n",
       "1                7                   7               0.046083   \n",
       "2                4                   1               0.030303   \n",
       "3                3                   0               0.028169   \n",
       "4                5                   4               0.032727   \n",
       "\n",
       "            ...            chargram_2_first_hits  chargram_8_hits  \\\n",
       "0           ...                                0                0   \n",
       "1           ...                                3                0   \n",
       "2           ...                                1                0   \n",
       "3           ...                                1                0   \n",
       "4           ...                                4                0   \n",
       "\n",
       "   chargram_8_early_hits  chargram_8_first_hits  chargram_4_hits  \\\n",
       "0                      0                      0                0   \n",
       "1                      0                      0                0   \n",
       "2                      0                      0                0   \n",
       "3                      0                      0                0   \n",
       "4                      0                      0                0   \n",
       "\n",
       "   chargram_4_early_hits  chargram_4_first_hits  chargram_16_hits  \\\n",
       "0                      0                      0                 0   \n",
       "1                      0                      0                 0   \n",
       "2                      0                      0                 0   \n",
       "3                      0                      0                 0   \n",
       "4                      0                      0                 0   \n",
       "\n",
       "   chargram_16_early_hits  chargram_16_first_hits  \n",
       "0                       0                       0  \n",
       "1                       0                       0  \n",
       "2                       0                       0  \n",
       "3                       0                       0  \n",
       "4                       0                       0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 49)\n",
      "(49972,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_str_cols(df): # df should be X, e.g. X_train or X_dev\n",
    "    del df[\"articleBody\"]\n",
    "    del df[\"Headline\"]\n",
    "    for col_name in df.columns:\n",
    "        if \"___\" == col_name[0:3]:\n",
    "            del df[col_name]\n",
    "#del_str_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 50)\n"
     ]
    }
   ],
   "source": [
    "Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "print(Xy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>___clean_headline</th>\n",
       "      <th>___clean_headline_tokenized_lemmas</th>\n",
       "      <th>___clean_body</th>\n",
       "      <th>___clean_body_tokenized_lemmas</th>\n",
       "      <th>bin_count</th>\n",
       "      <th>bin_count_early</th>\n",
       "      <th>bin_count_stopless</th>\n",
       "      <th>word_overlap_features</th>\n",
       "      <th>...</th>\n",
       "      <th>chargram_8_hits</th>\n",
       "      <th>chargram_8_early_hits</th>\n",
       "      <th>chargram_8_first_hits</th>\n",
       "      <th>chargram_4_hits</th>\n",
       "      <th>chargram_4_early_hits</th>\n",
       "      <th>chargram_4_first_hits</th>\n",
       "      <th>chargram_16_hits</th>\n",
       "      <th>chargram_16_early_hits</th>\n",
       "      <th>chargram_16_first_hits</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\n\\n...</td>\n",
       "      <td>police find mass graves with at least 15 bodie...</td>\n",
       "      <td>[police, find, mass, graf, with, at, least, 15...</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "      <td>[danny, boyle, is, directing, the, untitled, f...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>[hundred, of, palestinian, flee, flood, in, ga...</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "      <td>[hundred, of, palestinian, were, evacuated, fr...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>[christian, bale, pass, on, role, of, steve, j...</td>\n",
       "      <td>30 year old moscow resident was hospitalized w...</td>\n",
       "      <td>[30, year, old, moscow, resident, wa, hospital...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "      <td>hbo and apple in talks for 15 month apple tv s...</td>\n",
       "      <td>[hbo, and, apple, in, talk, for, 15, month, ap...</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "      <td>[reuters, a, canadian, soldier, wa, shot, at, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>[spider, burrowed, through, tourist, s, stomac...</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "      <td>[fear, not, arachnophobes, the, story, of, bun...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  Police find mass graves with at least '15 bodi...   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...   \n",
       "4  Spider burrowed through tourist's stomach and ...   \n",
       "\n",
       "                                         articleBody  \\\n",
       "0  Danny Boyle is directing the untitled film\\n\\n...   \n",
       "1  Hundreds of Palestinians were evacuated from t...   \n",
       "2  30-year-old Moscow resident was hospitalized w...   \n",
       "3  (Reuters) - A Canadian soldier was shot at the...   \n",
       "4  Fear not arachnophobes, the story of Bunbury's...   \n",
       "\n",
       "                                   ___clean_headline  \\\n",
       "0  police find mass graves with at least 15 bodie...   \n",
       "1  hundreds of palestinians flee floods in gaza a...   \n",
       "2  christian bale passes on role of steve jobs ac...   \n",
       "3  hbo and apple in talks for 15 month apple tv s...   \n",
       "4  spider burrowed through tourist s stomach and ...   \n",
       "\n",
       "                  ___clean_headline_tokenized_lemmas  \\\n",
       "0  [police, find, mass, graf, with, at, least, 15...   \n",
       "1  [hundred, of, palestinian, flee, flood, in, ga...   \n",
       "2  [christian, bale, pass, on, role, of, steve, j...   \n",
       "3  [hbo, and, apple, in, talk, for, 15, month, ap...   \n",
       "4  [spider, burrowed, through, tourist, s, stomac...   \n",
       "\n",
       "                                       ___clean_body  \\\n",
       "0  danny boyle is directing the untitled film set...   \n",
       "1  hundreds of palestinians were evacuated from t...   \n",
       "2  30 year old moscow resident was hospitalized w...   \n",
       "3  reuters a canadian soldier was shot at the can...   \n",
       "4  fear not arachnophobes the story of bunbury s ...   \n",
       "\n",
       "                      ___clean_body_tokenized_lemmas  bin_count  \\\n",
       "0  [danny, boyle, is, directing, the, untitled, f...          2   \n",
       "1  [hundred, of, palestinian, were, evacuated, fr...         10   \n",
       "2  [30, year, old, moscow, resident, wa, hospital...          5   \n",
       "3  [reuters, a, canadian, soldier, wa, shot, at, ...          3   \n",
       "4  [fear, not, arachnophobes, the, story, of, bun...          9   \n",
       "\n",
       "   bin_count_early  bin_count_stopless  word_overlap_features    ...      \\\n",
       "0                0                   0               0.014085    ...       \n",
       "1                7                   7               0.046083    ...       \n",
       "2                4                   1               0.030303    ...       \n",
       "3                3                   0               0.028169    ...       \n",
       "4                5                   4               0.032727    ...       \n",
       "\n",
       "   chargram_8_hits  chargram_8_early_hits  chargram_8_first_hits  \\\n",
       "0                0                      0                      0   \n",
       "1                0                      0                      0   \n",
       "2                0                      0                      0   \n",
       "3                0                      0                      0   \n",
       "4                0                      0                      0   \n",
       "\n",
       "   chargram_4_hits  chargram_4_early_hits  chargram_4_first_hits  \\\n",
       "0                0                      0                      0   \n",
       "1                0                      0                      0   \n",
       "2                0                      0                      0   \n",
       "3                0                      0                      0   \n",
       "4                0                      0                      0   \n",
       "\n",
       "   chargram_16_hits  chargram_16_early_hits  chargram_16_first_hits     Stance  \n",
       "0                 0                       0                       0  unrelated  \n",
       "1                 0                       0                       0      agree  \n",
       "2                 0                       0                       0  unrelated  \n",
       "3                 0                       0                       0  unrelated  \n",
       "4                 0                       0                       0   disagree  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xy_train = Xy_train[Xy_train[\"Stance\"] != \"unrelated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 50)\n"
     ]
    }
   ],
   "source": [
    "print(Xy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 49)\n",
      "(49972,)\n"
     ]
    }
   ],
   "source": [
    "y_train = Xy_train[\"Stance\"]\n",
    "X_train = Xy_train.drop(\"Stance\", axis=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gui/anaconda3/envs/nlu4/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import vader\n",
    "sid = vader.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49972/49972 [00:44<00:00, 1132.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49972/49972 [06:29<00:00, 128.14it/s]\n"
     ]
    }
   ],
   "source": [
    "def vader_polarity_scores(df, text_col_name, col_name_prefix):\n",
    "    pol_scores = df[text_col_name].progress_apply(lambda hl: pd.Series(sid.polarity_scores(hl)))\n",
    "    cols = pol_scores.columns\n",
    "    new_cols = []\n",
    "    for col_name in cols:\n",
    "        new_cols.append(\"vader_\"+col_name_prefix+\"_\"+col_name)\n",
    "    pol_scores.columns = new_cols\n",
    "    return pol_scores\n",
    "\n",
    "vader_hl_df = vader_polarity_scores(X_train, \"Headline\", \"hl\")\n",
    "vader_body_df = vader_polarity_scores(X_train, \"articleBody\", \"body\")\n",
    "X_train = pd.concat([X_train, vader_hl_df, vader_body_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_str_cols(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 51)\n",
      "(49972,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = sklearn.model_selection.train_test_split(X_train, y_train, test_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44974, 51)\n",
      "(44974,)\n",
      "(4998, 51)\n",
      "(4998,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_count</th>\n",
       "      <th>bin_count_early</th>\n",
       "      <th>bin_count_stopless</th>\n",
       "      <th>word_overlap_features</th>\n",
       "      <th>wrf_hl_fake</th>\n",
       "      <th>wrf_hl_fraud</th>\n",
       "      <th>wrf_hl_hoax</th>\n",
       "      <th>wrf_hl_false</th>\n",
       "      <th>wrf_hl_deny</th>\n",
       "      <th>wrf_hl_denies</th>\n",
       "      <th>...</th>\n",
       "      <th>chargram_16_early_hits</th>\n",
       "      <th>chargram_16_first_hits</th>\n",
       "      <th>vader_hl_neg</th>\n",
       "      <th>vader_hl_neu</th>\n",
       "      <th>vader_hl_pos</th>\n",
       "      <th>vader_hl_compound</th>\n",
       "      <th>vader_body_neg</th>\n",
       "      <th>vader_body_neu</th>\n",
       "      <th>vader_body_pos</th>\n",
       "      <th>vader_body_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44610</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.8658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43957</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.9927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49559</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.7978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.5520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_count  bin_count_early  bin_count_stopless  word_overlap_features  \\\n",
       "44610          9                8                   4               0.057377   \n",
       "10499          4                3                   1               0.023256   \n",
       "43957          8                5                   4               0.024465   \n",
       "49559          4                2                   1               0.009926   \n",
       "1851           1                1                   0               0.008403   \n",
       "\n",
       "       wrf_hl_fake  wrf_hl_fraud  wrf_hl_hoax  wrf_hl_false  wrf_hl_deny  \\\n",
       "44610            0             0            0             0            0   \n",
       "10499            0             0            0             0            0   \n",
       "43957            0             0            0             0            0   \n",
       "49559            0             0            0             0            0   \n",
       "1851             0             0            0             0            0   \n",
       "\n",
       "       wrf_hl_denies         ...           chargram_16_early_hits  \\\n",
       "44610              0         ...                                0   \n",
       "10499              0         ...                                0   \n",
       "43957              0         ...                                0   \n",
       "49559              0         ...                                0   \n",
       "1851               0         ...                                0   \n",
       "\n",
       "       chargram_16_first_hits  vader_hl_neg  vader_hl_neu  vader_hl_pos  \\\n",
       "44610                       0         0.145         0.855           0.0   \n",
       "10499                       0         0.000         1.000           0.0   \n",
       "43957                       0         0.062         0.938           0.0   \n",
       "49559                       0         0.000         1.000           0.0   \n",
       "1851                        0         0.000         1.000           0.0   \n",
       "\n",
       "       vader_hl_compound  vader_body_neg  vader_body_neu  vader_body_pos  \\\n",
       "44610            -0.2960           0.085           0.873           0.042   \n",
       "10499             0.0000           0.004           0.955           0.040   \n",
       "43957            -0.0516           0.141           0.782           0.076   \n",
       "49559             0.0000           0.060           0.866           0.074   \n",
       "1851              0.0000           0.000           0.972           0.028   \n",
       "\n",
       "       vader_body_compound  \n",
       "44610              -0.8658  \n",
       "10499               0.8325  \n",
       "43957              -0.9927  \n",
       "49559               0.7978  \n",
       "1851                0.5520  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       43994.9336            1.77m\n",
      "         2       39359.5278            1.74m\n",
      "         3       35615.7635            1.72m\n",
      "         4       32550.1051            1.72m\n",
      "         5       30021.5762            1.69m\n",
      "         6       27912.1975            1.69m\n",
      "         7       26129.6700            1.67m\n",
      "         8       24628.2887            1.67m\n",
      "         9       23356.7232            1.67m\n",
      "        10       22285.5580            1.67m\n",
      "        20       17050.6981            1.56m\n",
      "        30       15502.6237            1.44m\n",
      "        40       14804.4956            1.36m\n",
      "        50       14355.5579            1.29m\n",
      "        60       13989.2767            1.23m\n",
      "        70       13681.9988            1.15m\n",
      "        80       13405.1976            1.04m\n",
      "        90       13182.4676           57.94s\n",
      "       100       12973.7804           53.82s\n",
      "       200       11321.6110            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              presort='auto', random_state=14128, subsample=1.0,\n",
       "              verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.70      0.31      0.43       331\n",
      "   disagree       0.57      0.08      0.14       102\n",
      "    discuss       0.71      0.86      0.78       876\n",
      "  unrelated       0.96      0.98      0.97      3689\n",
      "\n",
      "avg / total       0.89      0.90      0.89      4998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, preds))\n",
    "# With VADER sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted accuracy: 0.8281232492997199 (1847.75 out of 2231.25)\n"
     ]
    }
   ],
   "source": [
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=8,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn.ensemble.RandomForestClassifier(n_estimators=400, n_jobs=8, random_state=42)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agree       0.75      0.36      0.48       331\n",
      "   disagree       0.63      0.12      0.20       102\n",
      "    discuss       0.72      0.87      0.79       876\n",
      "  unrelated       0.96      0.99      0.97      3689\n",
      "\n",
      "avg / total       0.90      0.90      0.89      4998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = crf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted accuracy: 0.836750700280112 (1867.0 out of 2231.25)\n"
     ]
    }
   ],
   "source": [
    "score, max_score = score_4class(y_dev, preds)\n",
    "print(\"Weighted accuracy: \"+str(score/max_score)+\" (\"+str(score)+\" out of \"+str(max_score)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn.ensemble.RandomForestClassifier(n_estimators=200, n_jobs=8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = crf.predict(X_dev)\n",
    "print(classification_report(y_dev, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-class problem:\n",
    "# By guessing most common category (unrelated), we would achieve approx. 73% accuracy. The baseline model achieves 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
